{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Z4udhSnyN3l1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a52d0d4-6a3a-485f-da7c-be3ff39f2359"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/Kaggle\"\n",
        "# /content/drive/My Drive/Kaggle is the path where kaggle.json is present in the Google Drive"
      ],
      "metadata": {
        "id": "J1X4E0v4N42v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.920290Z",
          "iopub.execute_input": "2023-01-18T08:52:39.921409Z",
          "iopub.status.idle": "2023-01-18T08:52:39.928501Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.921379Z",
          "shell.execute_reply": "2023-01-18T08:52:39.927486Z"
        },
        "trusted": true,
        "id": "PhVsCvJ7NMrT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG,self).__init__()\n",
        "        \n",
        "        ## using multiple layers since the early ones measure relatively lower level features like edges and later layers which measure high level features\n",
        "        ## this helps the neural network to take both lower level and higher level correlations in account when computing style\n",
        "        #self.chosen_features = ['0','5','10','19','28'] ## this is usually suggested \n",
        "        \n",
        "        self.chosen_features = ['3','8','17','26'] ## However, I got better result with these\n",
        "        \n",
        "        self.model = models.vgg19(pretrained=True).features[:29] #dropping the classification head as well as a few convolution layers\n",
        "        \n",
        "    def forward(self,x):\n",
        "        features =[]\n",
        "        \n",
        "        for layer_num, layer in enumerate(self.model):\n",
        "            x= layer(x)\n",
        "            \n",
        "            if str(layer_num) in self.chosen_features:\n",
        "                features.append(x)\n",
        "        \n",
        "        return features"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.930016Z",
          "iopub.execute_input": "2023-01-18T08:52:39.930708Z",
          "iopub.status.idle": "2023-01-18T08:52:39.941004Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.930667Z",
          "shell.execute_reply": "2023-01-18T08:52:39.939957Z"
        },
        "trusted": true,
        "id": "p85icfzENMrT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_name):\n",
        "    image = Image.open(image_name)\n",
        "    image = loader(image).unsqueeze(0) ## adding additional dimenstion for the batch size\n",
        "    return image.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.942357Z",
          "iopub.execute_input": "2023-01-18T08:52:39.942926Z",
          "iopub.status.idle": "2023-01-18T08:52:39.951708Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.942810Z",
          "shell.execute_reply": "2023-01-18T08:52:39.950657Z"
        },
        "trusted": true,
        "id": "T-ZWPTT0NMrU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "image_size_h = 300\n",
        "image_size_w = 450"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.955192Z",
          "iopub.execute_input": "2023-01-18T08:52:39.955549Z",
          "iopub.status.idle": "2023-01-18T08:52:39.964480Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.955519Z",
          "shell.execute_reply": "2023-01-18T08:52:39.963505Z"
        },
        "trusted": true,
        "id": "MQh6X6nBNMrU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((image_size_h,image_size_w)),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.966086Z",
          "iopub.execute_input": "2023-01-18T08:52:39.966576Z",
          "iopub.status.idle": "2023-01-18T08:52:39.975523Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.966542Z",
          "shell.execute_reply": "2023-01-18T08:52:39.974202Z"
        },
        "trusted": true,
        "id": "06jLWGL9NMrU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_img = load_image(\"/content/drive/MyDrive/Kaggle/content images/best bird.jpeg\")\n",
        "style_img= load_image(\"/content/drive/MyDrive/Kaggle/cstyle images/Duchamp_-_Nude_Descending_a_Staircase.jpg\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.978660Z",
          "iopub.execute_input": "2023-01-18T08:52:39.978955Z",
          "iopub.status.idle": "2023-01-18T08:52:40.053391Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.978930Z",
          "shell.execute_reply": "2023-01-18T08:52:40.052371Z"
        },
        "trusted": true,
        "id": "NWNAW0QpNMrU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#freezing the model's parameters and setting it to evaluation mode\n",
        "\n",
        "model = VGG().to(device).eval().requires_grad_(False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:40.054948Z",
          "iopub.execute_input": "2023-01-18T08:52:40.055362Z",
          "iopub.status.idle": "2023-01-18T08:52:41.973343Z",
          "shell.execute_reply.started": "2023-01-18T08:52:40.055328Z",
          "shell.execute_reply": "2023-01-18T08:52:41.972331Z"
        },
        "trusted": true,
        "id": "0CV-RGyYNMrV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:41.974844Z",
          "iopub.execute_input": "2023-01-18T08:52:41.975571Z",
          "iopub.status.idle": "2023-01-18T08:52:41.982531Z",
          "shell.execute_reply.started": "2023-01-18T08:52:41.975529Z",
          "shell.execute_reply": "2023-01-18T08:52:41.981101Z"
        },
        "trusted": true,
        "id": "FjqBaaGmNMrV",
        "outputId": "03bd2360-7768-463c-f6c2-0ef2e40ad7b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## since I have frozen the model, the only thing that needs to be changed is the generated image\n",
        "\n",
        "generated = original_img.clone().requires_grad_(True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:41.986480Z",
          "iopub.execute_input": "2023-01-18T08:52:41.986900Z",
          "iopub.status.idle": "2023-01-18T08:52:41.995471Z",
          "shell.execute_reply.started": "2023-01-18T08:52:41.986865Z",
          "shell.execute_reply": "2023-01-18T08:52:41.994463Z"
        },
        "trusted": true,
        "id": "p4iaC-hYNMrW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## using the noise vector requires more computation as well as a better hardware to give a satisfiable result\n",
        "\n",
        "#generated = torch.randn(original_img.shape, device=device, requires_grad=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:41.997093Z",
          "iopub.execute_input": "2023-01-18T08:52:41.997567Z",
          "iopub.status.idle": "2023-01-18T08:52:42.006516Z",
          "shell.execute_reply.started": "2023-01-18T08:52:41.997531Z",
          "shell.execute_reply": "2023-01-18T08:52:42.005415Z"
        },
        "trusted": true,
        "id": "rI4RDtXINMrW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "total_steps = 60000\n",
        "learning_rate = 0.0001\n",
        "alpha = 1\n",
        "beta = 0.01\n",
        "optimizer = optim.Adam([generated], lr= learning_rate)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:42.008178Z",
          "iopub.execute_input": "2023-01-18T08:52:42.008562Z",
          "iopub.status.idle": "2023-01-18T08:52:42.018535Z",
          "shell.execute_reply.started": "2023-01-18T08:52:42.008521Z",
          "shell.execute_reply": "2023-01-18T08:52:42.017534Z"
        },
        "trusted": true,
        "id": "ESM4iFzUNMrX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Style is defined as correlation between activations across channels.\n",
        "\n",
        "Correlation tells us which of the high level features tend to occur together or never occur together. <br> Here, we use the degree of correlation between channels as a measure of style. We construct a style loss which minimizes the Gram Matrix(which is a correlation matrix) of the style and the generated images so that the generated image learns a similar correlation between the activations of the style in a particular layer as the style.\n",
        "<br>\n",
        "Here, the Gram Matrix is calculating the unnormalized Cross covariance, which is used here as a proxy for correlation."
      ],
      "metadata": {
        "id": "_FLXAsQu7PaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(total_steps):\n",
        "    generated_features = model(generated)\n",
        "    original_img_features = model(original_img)\n",
        "    style_features = model(style_img)\n",
        "    # During each step, the code is passing the generated, original, and style images through the model (CNN) to generate their respective features.\n",
        "\n",
        "    style_loss = 0\n",
        "    original_loss =0\n",
        "    \n",
        "    for gen_feature, orig_feature, style_feature in zip(generated_features, original_img_features, style_features):\n",
        "        batch_size , channel, height, width = gen_feature.shape\n",
        "        \n",
        "        original_loss += torch.mean((gen_feature-orig_feature)**2) #also works with Mean Absolute Error loss\n",
        "        \n",
        "        ## Gram Matrix for Generated image\n",
        "        \n",
        "        G= gen_feature.view(channel, height*width).mm(gen_feature.view(channel,height*width).t())\n",
        "        \n",
        "        ## Gram Matrix for Style image\n",
        "\n",
        "        S= style_feature.view(channel, height*width).mm(style_feature.view(channel,height*width).t())\n",
        "\n",
        "        style_loss +=torch.mean((G-S)**2)\n",
        "        \n",
        "    total_loss = alpha*original_loss +beta*style_loss\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if step % 200 == 0:\n",
        "        print(total_loss)\n",
        "        save_image(generated,f\"generated{step}.jpeg\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:42.020151Z",
          "iopub.execute_input": "2023-01-18T08:52:42.020574Z",
          "iopub.status.idle": "2023-01-18T09:59:23.640825Z",
          "shell.execute_reply.started": "2023-01-18T08:52:42.020507Z",
          "shell.execute_reply": "2023-01-18T09:59:23.639132Z"
        },
        "trusted": true,
        "id": "La9ZiiM4NMrX",
        "outputId": "3978aa54-9912-4cb2-daa4-1eb35ae0baf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(615628., device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(251591.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(134070.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(84691.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(61132.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(46942.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(37134.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(29935.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(24484.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(20278.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(17007.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(14437.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(12392.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(10754.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(9430.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8352.6338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7469.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6743.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6139.4307, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5632.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5200.4033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4827.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4501.2642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4212.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3954.6597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3720.1379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3505.5796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3308.6765, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3125.7756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2955.3311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2795.8005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2647.0444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2508.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2377.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2256.0264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2140.6279, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2030.7460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1926.7178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1828.1121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1733.7313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1643.2042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1557.3416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1474.8392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1395.4419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1319.6176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1247.7666, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1179.7644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1114.6780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1052.5594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(993.6390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(937.2458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(883.1097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(831.6744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(783.0089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(736.7476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(692.9246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(651.5711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(612.7996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(576.4721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(542.5256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(510.8361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(481.3714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(453.8301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(428.4377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(404.7574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(382.8316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(362.4032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(343.3579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(325.7624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(309.5976, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(294.6717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(280.9056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(268.1697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(256.4424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(245.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(235.7517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(226.6883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(218.2585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(210.5189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(203.2953, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(196.6107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(190.3946, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(184.7247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(179.4432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(174.6266, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w5QqsGKxDgrQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}