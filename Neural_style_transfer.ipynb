{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Z4udhSnyN3l1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a52d0d4-6a3a-485f-da7c-be3ff39f2359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/Kaggle\"\n",
        "# /content/drive/My Drive/Kaggle is the path where kaggle.json is present in the Google Drive"
      ],
      "metadata": {
        "id": "J1X4E0v4N42v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.920290Z",
          "iopub.execute_input": "2023-01-18T08:52:39.921409Z",
          "iopub.status.idle": "2023-01-18T08:52:39.928501Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.921379Z",
          "shell.execute_reply": "2023-01-18T08:52:39.927486Z"
        },
        "trusted": true,
        "id": "PhVsCvJ7NMrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG,self).__init__()\n",
        "        \n",
        "        ## using multiple layers since the early ones measure relatively lower level features like edges and later layers which measure high level features\n",
        "        ## this helps the neural network to take both lower level and higher level correlations in account when computing style\n",
        "        #self.chosen_features = ['0','5','10','19','28'] ## this is usually suggested \n",
        "        \n",
        "        self.chosen_features = ['3','8','17','26'] ## However, I got better result with these\n",
        "        \n",
        "        self.model = models.vgg19(pretrained=True).features[:29] #dropping the classification head as well as a few convolution layers\n",
        "        \n",
        "    def forward(self,x):\n",
        "        features =[]\n",
        "        \n",
        "        for layer_num, layer in enumerate(self.model):\n",
        "            x= layer(x)\n",
        "            \n",
        "            if str(layer_num) in self.chosen_features:\n",
        "                features.append(x)\n",
        "        \n",
        "        return features"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.930016Z",
          "iopub.execute_input": "2023-01-18T08:52:39.930708Z",
          "iopub.status.idle": "2023-01-18T08:52:39.941004Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.930667Z",
          "shell.execute_reply": "2023-01-18T08:52:39.939957Z"
        },
        "trusted": true,
        "id": "p85icfzENMrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_name):\n",
        "    image = Image.open(image_name)\n",
        "    image = loader(image).unsqueeze(0) ## adding additional dimension for the batch size\n",
        "    return image.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.942357Z",
          "iopub.execute_input": "2023-01-18T08:52:39.942926Z",
          "iopub.status.idle": "2023-01-18T08:52:39.951708Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.942810Z",
          "shell.execute_reply": "2023-01-18T08:52:39.950657Z"
        },
        "trusted": true,
        "id": "T-ZWPTT0NMrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "image_size_h = 300\n",
        "image_size_w = 450"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.955192Z",
          "iopub.execute_input": "2023-01-18T08:52:39.955549Z",
          "iopub.status.idle": "2023-01-18T08:52:39.964480Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.955519Z",
          "shell.execute_reply": "2023-01-18T08:52:39.963505Z"
        },
        "trusted": true,
        "id": "MQh6X6nBNMrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((image_size_h,image_size_w)),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.966086Z",
          "iopub.execute_input": "2023-01-18T08:52:39.966576Z",
          "iopub.status.idle": "2023-01-18T08:52:39.975523Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.966542Z",
          "shell.execute_reply": "2023-01-18T08:52:39.974202Z"
        },
        "trusted": true,
        "id": "06jLWGL9NMrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_img = load_image(\"/content/drive/MyDrive/Kaggle/content images/best bird.jpeg\")\n",
        "style_img= load_image(\"/content/drive/MyDrive/Kaggle/cstyle images/Duchamp_-_Nude_Descending_a_Staircase.jpg\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:39.978660Z",
          "iopub.execute_input": "2023-01-18T08:52:39.978955Z",
          "iopub.status.idle": "2023-01-18T08:52:40.053391Z",
          "shell.execute_reply.started": "2023-01-18T08:52:39.978930Z",
          "shell.execute_reply": "2023-01-18T08:52:40.052371Z"
        },
        "trusted": true,
        "id": "NWNAW0QpNMrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#freezing the model's parameters and setting it to evaluation mode\n",
        "\n",
        "model = VGG().to(device).eval().requires_grad_(False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:40.054948Z",
          "iopub.execute_input": "2023-01-18T08:52:40.055362Z",
          "iopub.status.idle": "2023-01-18T08:52:41.973343Z",
          "shell.execute_reply.started": "2023-01-18T08:52:40.055328Z",
          "shell.execute_reply": "2023-01-18T08:52:41.972331Z"
        },
        "trusted": true,
        "id": "0CV-RGyYNMrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:41.974844Z",
          "iopub.execute_input": "2023-01-18T08:52:41.975571Z",
          "iopub.status.idle": "2023-01-18T08:52:41.982531Z",
          "shell.execute_reply.started": "2023-01-18T08:52:41.975529Z",
          "shell.execute_reply": "2023-01-18T08:52:41.981101Z"
        },
        "trusted": true,
        "id": "FjqBaaGmNMrV",
        "outputId": "03bd2360-7768-463c-f6c2-0ef2e40ad7b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## since I have frozen the model, the only thing that needs to be changed is the generated image\n",
        "\n",
        "generated = original_img.clone().requires_grad_(True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:41.986480Z",
          "iopub.execute_input": "2023-01-18T08:52:41.986900Z",
          "iopub.status.idle": "2023-01-18T08:52:41.995471Z",
          "shell.execute_reply.started": "2023-01-18T08:52:41.986865Z",
          "shell.execute_reply": "2023-01-18T08:52:41.994463Z"
        },
        "trusted": true,
        "id": "p4iaC-hYNMrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## using the noise vector requires more computation as well as a better hardware to give a satisfiable result\n",
        "\n",
        "#generated = torch.randn(original_img.shape, device=device, requires_grad=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:41.997093Z",
          "iopub.execute_input": "2023-01-18T08:52:41.997567Z",
          "iopub.status.idle": "2023-01-18T08:52:42.006516Z",
          "shell.execute_reply.started": "2023-01-18T08:52:41.997531Z",
          "shell.execute_reply": "2023-01-18T08:52:42.005415Z"
        },
        "trusted": true,
        "id": "rI4RDtXINMrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "total_steps = 60000\n",
        "learning_rate = 0.0001\n",
        "alpha = 1\n",
        "beta = 0.01\n",
        "optimizer = optim.Adam([generated], lr= learning_rate)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:42.008178Z",
          "iopub.execute_input": "2023-01-18T08:52:42.008562Z",
          "iopub.status.idle": "2023-01-18T08:52:42.018535Z",
          "shell.execute_reply.started": "2023-01-18T08:52:42.008521Z",
          "shell.execute_reply": "2023-01-18T08:52:42.017534Z"
        },
        "trusted": true,
        "id": "ESM4iFzUNMrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Style is defined as correlation between activations across channels.\n",
        "\n",
        "Correlation tells us which of the high level features tend to occur together or never occur together. <br> Here, we use the degree of correlation between channels as a measure of style. We construct a style loss which minimizes the Gram Matrix(which is a correlation matrix) of the style and the generated images so that the generated image learns a similar correlation between the activations of the style in a particular layer as the style.\n",
        "<br>\n",
        "Here, the Gram Matrix is calculating the unnormalized Cross covariance, which is used here as a proxy for correlation."
      ],
      "metadata": {
        "id": "_FLXAsQu7PaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(total_steps):\n",
        "    generated_features = model(generated)\n",
        "    original_img_features = model(original_img)\n",
        "    style_features = model(style_img)\n",
        "    # During each step, the code is passing the generated, original, and style images through the model (CNN) to generate their respective features.\n",
        "\n",
        "    style_loss = 0\n",
        "    original_loss =0\n",
        "    \n",
        "    for generated_feature, original_feature, style_feature in zip(generated_features, original_img_features, style_features):\n",
        "        batch_size , channel, height, width = generated_feature.shape\n",
        "        \n",
        "        original_loss += torch.mean((generated_feature-original_feature)**2) #also works with Mean Absolute Error loss\n",
        "        \n",
        "        ## Gram Matrix for Generated image\n",
        "        # Here, we are multiplying ever pixel value from each channel with every other channel in the generated features\n",
        "\n",
        "        G= generated_feature.view(channel, height*width).mm(generated_feature.view(channel,height*width).t())\n",
        "                \n",
        "        ## Gram Matrix for Style image\n",
        "        # Here, we are multiplying ever pixel value from each channel with every other channel in the style features\n",
        "\n",
        "        S= style_feature.view(channel, height*width).mm(style_feature.view(channel,height*width).t())\n",
        "\n",
        "        style_loss +=torch.mean((G-S)**2)\n",
        "        \n",
        "    total_loss = alpha*original_loss +beta*style_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if step % 200 == 0:\n",
        "        print(total_loss)\n",
        "        save_image(generated,f\"generated{step}.jpeg\")\n",
        "        "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-18T08:52:42.020151Z",
          "iopub.execute_input": "2023-01-18T08:52:42.020574Z",
          "iopub.status.idle": "2023-01-18T09:59:23.640825Z",
          "shell.execute_reply.started": "2023-01-18T08:52:42.020507Z",
          "shell.execute_reply": "2023-01-18T09:59:23.639132Z"
        },
        "trusted": true,
        "id": "La9ZiiM4NMrX",
        "outputId": "8a68ec65-2dc6-4765-efac-40f5bb65eb3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(138.6207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(136.4139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(134.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(132.4008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(130.5687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(128.8168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(127.1105, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(125.5054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(123.9877, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZECQ_DJQMApb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}